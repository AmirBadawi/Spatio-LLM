{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def parse_trip_summary(text):\n",
    "    \"\"\"\n",
    "    Extract key fields from a single trip summary.\n",
    "    Here we extract the transport mode and keep the full summary.\n",
    "    You can extend this to parse other fields (e.g., start/end times, distance).\n",
    "    \"\"\"\n",
    "    mode_match = re.search(r\"- Transport Mode:\\s*(.*)\", text)\n",
    "    transport_mode = mode_match.group(1).strip() if mode_match else \"Unknown\"\n",
    "    return {\n",
    "        \"transport_mode\": transport_mode,\n",
    "        \"summary\": text.strip()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trip summary counts by transport mode:\n",
      "transport_mode\n",
      "walk        76\n",
      "bus         50\n",
      "bike        35\n",
      "car         28\n",
      "subway      20\n",
      "taxi        11\n",
      "train        6\n",
      "airplane     2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Read the trip summaries from file\n",
    "file_path = \"./sub_trip_summaries.txt\"  # Adjust the path if needed\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "# Each trip summary is assumed to be separated by two newlines.\n",
    "trip_texts = [t.strip() for t in content.strip().split(\"\\n\\n\") if t.strip()]\n",
    "\n",
    "# Parse each trip summary into a structured dict.\n",
    "data = [parse_trip_summary(trip) for trip in trip_texts]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Trip summary counts by transport mode:\")\n",
    "print(df['transport_mode'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated transport mode counts:\n",
      "transport_mode\n",
      "walk      76\n",
      "bus       50\n",
      "car       39\n",
      "bike      35\n",
      "others    28\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define mappings explicitly\n",
    "mode_mapping = {\n",
    "    'taxi': 'car'\n",
    "}\n",
    "\n",
    "main_classes = {\"walk\", \"bike\", \"bus\", \"car\"}\n",
    "\n",
    "# First, replace 'taxi' with 'car'\n",
    "df['transport_mode'] = df['transport_mode'].replace(mode_mapping)\n",
    "\n",
    "# Then, assign 'others' to modes not in main_classes\n",
    "df['transport_mode'] = df['transport_mode'].where(df['transport_mode'].isin(main_classes), 'others')\n",
    "\n",
    "\n",
    "print(\"Updated transport mode counts:\")\n",
    "print(df['transport_mode'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "# Initialize the Azure OpenAI client\n",
    "azure_openai = AzureOpenAI(\n",
    "    azure_endpoint=\"https://intelligencia-openai-lab02.openai.azure.com/\",\n",
    "    api_key=\"049425cc99184a619ff068082279749f\",\n",
    "    api_version=\"2024-02-15-preview\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced dataset counts:\n",
      "transport_mode\n",
      "bike      40\n",
      "bus       40\n",
      "car       40\n",
      "others    40\n",
      "walk      40\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Set the target count for each class after balancing.\n",
    "target_count = 40\n",
    "\n",
    "# Function to call Azure OpenAI to generate a new trip summary based on a seed.\n",
    "def generate_sample_via_chatgpt(seed_summary, transport_mode):\n",
    "    \"\"\"\n",
    "    Generate a new trip summary using Azure OpenAI based on a seed summary.\n",
    "    Explicitly ensures the generated summary matches the provided transport mode.\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        f\"You are a trip summary augmentation assistant.\\n\\n\"\n",
    "        f\"Generate a new trip summary strictly following the structure below. \"\n",
    "        f\"The transport mode must be explicitly '{transport_mode}' and the details must be realistic \"\n",
    "        f\"and consistent with this transport mode (choose from 'walk', 'bike', 'bus', 'car', 'train').\\n\\n\"\n",
    "        \"Template:\\n\"\n",
    "        \"Trip Summary:\\n\"\n",
    "        \"- Start: YYYY-MM-DD HH:MM:SS at [Start Location Address]\\n\"\n",
    "        \"- End: YYYY-MM-DD HH:MM:SS at [End Location Address]\\n\"\n",
    "        \"- Duration: X days HH:MM:SS\\n\"\n",
    "        \"- Distance: X.XX km\\n\"\n",
    "        \"- Average Speed: XX.XX km/h\\n\"\n",
    "        \"- Average Bearing Change: XX.XX°\\n\"\n",
    "        \"- Max Speed: XX.XX km/h\\n\"\n",
    "        \"- Min Speed: XX.XX km/h\\n\"\n",
    "        \"- Speed Variability: XX.XX km/h\\n\"\n",
    "        \"- Average Acceleration: X.XX m/s²\\n\"\n",
    "        \"- Max Acceleration: XX.XX m/s²\\n\"\n",
    "        \"- Number of Turns: XX\\n\"\n",
    "        \"- Turn Rate: XX.XX turns/min\\n\"\n",
    "        \"- Average Turn Angle: XX.XX°\\n\"\n",
    "        \"- Turn Angle Variability: XX.XX°\\n\"\n",
    "        f\"- Transport Mode: {transport_mode}\\n\\n\"\n",
    "        f\"Example Trip Summary for reference:\\n{seed_summary}\\n\\n\"\n",
    "        \"Now generate the new trip summary:\"\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a trip summary augmentation assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    response = azure_openai.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages,\n",
    "        temperature=0.7,\n",
    "        max_tokens=300\n",
    "    )\n",
    "\n",
    "    new_summary = response.choices[0].message.content.strip()\n",
    "\n",
    "    # Ensure explicitly correct transport mode at the end (extra validation):\n",
    "    summary_lines = new_summary.splitlines()\n",
    "    corrected_summary = \"\\n\".join(\n",
    "        line for line in summary_lines if not line.strip().startswith(\"- Transport Mode:\")\n",
    "    )\n",
    "    corrected_summary += f\"\\n- Transport Mode: {transport_mode}\"\n",
    "\n",
    "    return corrected_summary\n",
    "\n",
    "# Assume df is your DataFrame containing trip summaries with at least the following columns:\n",
    "# 'summary' (the text of the trip summary) and 'transport_mode'\n",
    "# Also assume you have already transformed transport_mode so that only main classes remain, e.g., \"walk\", \"bike\", \"bus\", \"car\", \"Mixed\", and \"others\".\n",
    "\n",
    "# Step 1: Slightly undersample the majority classes.\n",
    "undersampled_list = []\n",
    "for mode, group in df.groupby('transport_mode'):\n",
    "    if len(group) > target_count:\n",
    "        # For classes above target, sample without replacement.\n",
    "        undersampled_group = group.sample(target_count, random_state=42)\n",
    "    else:\n",
    "        undersampled_group = group.copy()\n",
    "    undersampled_list.append(undersampled_group)\n",
    "undersampled_df = pd.concat(undersampled_list).reset_index(drop=True)\n",
    "\n",
    "# Step 2: For classes with fewer than target_count samples, augment using ChatGPT.\n",
    "augmented_samples = []\n",
    "for mode, group in undersampled_df.groupby('transport_mode'):\n",
    "    current_count = len(group)\n",
    "    if current_count < target_count:\n",
    "        num_to_generate = target_count - current_count\n",
    "        seed_samples = group['summary'].tolist()\n",
    "        for _ in range(num_to_generate):\n",
    "            seed = random.choice(seed_samples)\n",
    "            new_sample = generate_sample_via_chatgpt(seed, transport_mode=mode)\n",
    "            augmented_samples.append({\n",
    "                'transport_mode': mode,\n",
    "                'summary': new_sample\n",
    "            })\n",
    "\n",
    "# Convert augmented samples into a DataFrame.\n",
    "augmented_df = pd.DataFrame(augmented_samples)\n",
    "\n",
    "# Combine the undersampled data with the augmented data.\n",
    "balanced_df = pd.concat([undersampled_df, augmented_df]).reset_index(drop=True)\n",
    "\n",
    "# Verify the new class counts.\n",
    "print(\"Balanced dataset counts:\")\n",
    "print(balanced_df['transport_mode'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced dataset saved as CSV: balanced_trip_summaries.csv\n",
      "Balanced dataset saved as JSONL: balanced_trip_summaries.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Save the balanced dataset to a CSV file.\n",
    "csv_file_path = \"balanced_trip_summaries.csv\"\n",
    "balanced_df.to_csv(csv_file_path, index=False)\n",
    "print(f\"Balanced dataset saved as CSV: {csv_file_path}\")\n",
    "\n",
    "# Save the balanced dataset to a JSONL file.\n",
    "jsonl_file_path = \"balanced_trip_summaries.jsonl\"\n",
    "balanced_df.to_json(jsonl_file_path, orient=\"records\", lines=True)\n",
    "print(f\"Balanced dataset saved as JSONL: {jsonl_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, now that our dataset is ready, let’s create a new notebook to run inference using the DeepSeek model. We’ll pass in our balanced dataset (balanced_trip_summaries.jsonl) to predict the transport mode. This will be done before fine-tuning, as I want to compare the model’s performance before and after fine-tuning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
